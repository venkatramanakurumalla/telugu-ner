import re
from typing import Dict, List, Optional, Tuple, Any

class AdvancedPronounEngine:
    def __init__(self):
        # 1. COMPREHENSIVE BASE FORMS (Nominative Case)
        self.base_forms = {
            # 1st Person
            '‡∞®‡±á‡∞®‡±Å': {'person': '1st', 'number': 'Singular', 'gender': 'Any', 'eng': 'I', 'formality': 'informal'},
            '‡∞®‡∞æ': {'person': '1st', 'number': 'Singular', 'gender': 'Any', 'eng': 'I', 'formality': 'oblique_base'},
            '‡∞Æ‡±á‡∞Æ‡±Å': {'person': '1st', 'number': 'Plural', 'gender': 'Any', 'eng': 'We', 'formality': 'formal'},
            '‡∞Æ‡∞®‡∞Æ‡±Å': {'person': '1st', 'number': 'Plural', 'gender': 'Any', 'eng': 'We', 'formality': 'inclusive'},
            '‡∞Æ‡∞®': {'person': '1st', 'number': 'Plural', 'gender': 'Any', 'eng': 'We', 'formality': 'oblique_inclusive'},
            
            # 2nd Person
            '‡∞®‡±Ä‡∞µ‡±Å': {'person': '2nd', 'number': 'Singular', 'gender': 'Any', 'eng': 'You', 'formality': 'formal'},
            '‡∞®‡±Å‡∞µ‡±ç‡∞µ‡±Å': {'person': '2nd', 'number': 'Singular', 'gender': 'Any', 'eng': 'You', 'formality': 'informal'},
            '‡∞®‡±Ä': {'person': '2nd', 'number': 'Singular', 'gender': 'Any', 'eng': 'You', 'formality': 'oblique_informal'},
            '‡∞Æ‡±Ä‡∞∞‡±Å': {'person': '2nd', 'number': 'Plural', 'gender': 'Any', 'eng': 'You', 'formality': 'respectful'},
            '‡∞Æ‡±Ä': {'person': '2nd', 'number': 'Plural', 'gender': 'Any', 'eng': 'You', 'formality': 'oblique_respectful'},
            '‡∞§‡∞Æ‡∞∞‡±Å': {'person': '2nd', 'number': 'Singular', 'gender': 'Any', 'eng': 'You', 'formality': 'high_respect'},
            '‡∞§‡∞Æ': {'person': '2nd', 'number': 'Singular', 'gender': 'Any', 'eng': 'You', 'formality': 'oblique_high_respect'},
            
            # 3rd Person
            '‡∞Ö‡∞§‡∞®‡±Å': {'person': '3rd', 'number': 'Singular', 'gender': 'Male', 'eng': 'He', 'formality': 'neutral'},
            '‡∞Ö‡∞§‡∞°‡±Å': {'person': '3rd', 'number': 'Singular', 'gender': 'Male', 'eng': 'He', 'formality': 'neutral'},
            '‡∞Ü‡∞Æ‡±Ü': {'person': '3rd', 'number': 'Singular', 'gender': 'Female', 'eng': 'She', 'formality': 'neutral'},
            '‡∞Ö‡∞¶‡∞ø': {'person': '3rd', 'number': 'Singular', 'gender': 'Neuter', 'eng': 'It/That', 'formality': 'neutral'},
            '‡∞á‡∞¶‡∞ø': {'person': '3rd', 'number': 'Singular', 'gender': 'Neuter', 'eng': 'It/This', 'formality': 'neutral'},
            '‡∞µ‡∞æ‡∞∞‡±Å': {'person': '3rd', 'number': 'Plural', 'gender': 'Human', 'eng': 'They', 'formality': 'respectful'},
            '‡∞µ‡∞æ‡∞≥‡±ç‡∞≥‡±Å': {'person': '3rd', 'number': 'Plural', 'gender': 'Human', 'eng': 'They', 'formality': 'informal'},
            '‡∞Ö‡∞µ‡∞ø': {'person': '3rd', 'number': 'Plural', 'gender': 'NonHuman', 'eng': 'Those', 'formality': 'neutral'},
            '‡∞á‡∞µ‡∞ø': {'person': '3rd', 'number': 'Plural', 'gender': 'NonHuman', 'eng': 'These', 'formality': 'neutral'},
            
            # Reflexive
            '‡∞§‡∞æ‡∞®‡±Å': {'person': '3rd', 'number': 'Singular', 'gender': 'Any', 'eng': 'Self', 'formality': 'reflexive'},
            '‡∞§‡∞®': {'person': '3rd', 'number': 'Singular', 'gender': 'Any', 'eng': 'Self', 'formality': 'oblique_reflexive'},
            
            # Interrogative
            '‡∞é‡∞µ‡∞∞‡±Å': {'person': 'interrogative', 'number': 'Any', 'gender': 'Human', 'eng': 'Who', 'formality': 'neutral'},
            '‡∞è‡∞Æ‡∞ø': {'person': 'interrogative', 'number': 'Any', 'gender': 'Neuter', 'eng': 'What', 'formality': 'neutral'},
            '‡∞é‡∞µ‡∞°‡±Å': {'person': 'interrogative', 'number': 'Singular', 'gender': 'Male', 'eng': 'Who', 'formality': 'informal'},
            '‡∞é‡∞µ‡∞§‡±Ü': {'person': 'interrogative', 'number': 'Singular', 'gender': 'Female', 'eng': 'Who', 'formality': 'informal'},
            
            # Demonstrative
            '‡∞Ö‡∞¶‡±á': {'person': '3rd', 'number': 'Singular', 'gender': 'Neuter', 'eng': 'That itself', 'formality': 'emphatic'},
            '‡∞á‡∞¶‡±á': {'person': '3rd', 'number': 'Singular', 'gender': 'Neuter', 'eng': 'This itself', 'formality': 'emphatic'},
        }

        # 2. COMPREHENSIVE CASE MAPPINGS
        self.case_patterns = {
            # Accusative (Object) - ni/nu endings
            'Accusative': [
                (r'‡∞®‡±ç‡∞®‡±Å$', '‡∞®‡±á‡∞®‡±Å'),  # Nannu (me)
                (r'‡∞Æ‡±ç‡∞Æ‡∞≤‡±ç‡∞®‡∞ø$', '‡∞Æ‡±á‡∞Æ‡±Å'), # Mammalni (us)
                (r'‡∞®‡±ç‡∞®‡±Å$', '‡∞®‡±Å‡∞µ‡±ç‡∞µ‡±Å'), # Ninnu (you)
                (r'‡∞Æ‡±ç‡∞Æ‡∞≤‡±ç‡∞®‡∞ø$', '‡∞Æ‡±Ä‡∞∞‡±Å'), # Mimmalni (you plural)
                (r'‡∞®‡±ç‡∞®‡∞ø$', '‡∞Ö‡∞§‡∞®‡±Å'),  # Atanni (him)
                (r'‡∞®‡±Å$', '‡∞Ü‡∞Æ‡±Ü'),    # Aamenu (her)
            ],
            
            # Dative (To/For) - ku/ki endings
            'Dative': [
                (r'‡∞ï‡±Å$', '‡∞®‡±á‡∞®‡±Å'),    # Naaku (to me)
                (r'‡∞ï‡±Å$', '‡∞Æ‡±á‡∞Æ‡±Å'),    # Maaku (to us)
                (r'‡∞ï‡±Å$', '‡∞®‡±Å‡∞µ‡±ç‡∞µ‡±Å'),  # Neeku (to you)
                (r'‡∞ï‡±Å$', '‡∞Æ‡±Ä‡∞∞‡±Å'),    # Meeku (to you plural)
                (r'‡∞ï‡∞ø$', '‡∞Ö‡∞§‡∞®‡±Å'),    # Ataniki (to him)
                (r'‡∞ï‡∞ø$', '‡∞Ü‡∞Æ‡±Ü'),     # Aameki (to her)
            ],
            
            # Genitive/Possessive (Of) - no specific ending, but oblique base
            'Genitive': [
                (r'^‡∞®‡∞æ', '‡∞®‡±á‡∞®‡±Å'),    # Naa (my)
                (r'^‡∞Æ‡∞æ', '‡∞Æ‡±á‡∞Æ‡±Å'),    # Maa (our)
                (r'^‡∞®‡±Ä', '‡∞®‡±Å‡∞µ‡±ç‡∞µ‡±Å'),  # Nee (your)
                (r'^‡∞Æ‡±Ä', '‡∞Æ‡±Ä‡∞∞‡±Å'),    # Mee (your plural)
                (r'^‡∞Ö‡∞§‡∞®‡∞ø', '‡∞Ö‡∞§‡∞®‡±Å'), # Atani (his)
                (r'^‡∞Ü‡∞Æ‡±Ü', '‡∞Ü‡∞Æ‡±Ü'),    # Aame (her)
                (r'^‡∞§‡∞®', '‡∞§‡∞æ‡∞®‡±Å'),    # Tana (his/her own)
            ],
            
            # Instrumental (With) - to/tho endings
            'Instrumental': [
                (r'‡∞§‡±ã$', '‡∞®‡±á‡∞®‡±Å'),    # Naatho (with me)
                (r'‡∞§‡±ã$', '‡∞Æ‡±á‡∞Æ‡±Å'),    # Maatho (with us)
                (r'‡∞§‡±ã$', '‡∞®‡±Å‡∞µ‡±ç‡∞µ‡±Å'),  # Neetho (with you)
                (r'‡∞§‡±ã$', '‡∞Æ‡±Ä‡∞∞‡±Å'),    # Meetho (with you plural)
            ],
            
            # Locative (In/At) - lo endings
            'Locative': [
                (r'‡∞≤‡±ã$', '‡∞®‡±á‡∞®‡±Å'),    # Naalo (in me)
                (r'‡∞≤‡±ã$', '‡∞Æ‡±á‡∞Æ‡±Å'),    # Maalo (in us)
                (r'‡∞≤‡±ã$', '‡∞®‡±Å‡∞µ‡±ç‡∞µ‡±Å'),  # Neelo (in you)
            ],
            
            # Ablative (From) - nundi endings
            'Ablative': [
                (r'‡∞®‡±Å‡∞Ç‡∞°‡∞ø$', '‡∞®‡±á‡∞®‡±Å'), # Naanundi (from me)
                (r'‡∞®‡±Å‡∞Ç‡∞°‡∞ø$', '‡∞Æ‡±á‡∞Æ‡±Å'), # Maanundi (from us)
                (r'‡∞®‡±Å‡∞Ç‡∞°‡∞ø$', '‡∞®‡±Å‡∞µ‡±ç‡∞µ‡±Å'), # Neenundi (from you)
            ]
        }

        # 3. COMPOUND SUFFIXES (Postpositions that attach to oblique forms)
        self.compound_suffixes = {
            '‡∞ï‡±ã‡∞∏‡∞Ç': 'for',
            '‡∞µ‡∞≤‡±ç‡∞≤': 'because of', 
            '‡∞¶‡±ç‡∞µ‡∞æ‡∞∞‡∞æ': 'through',
            '‡∞ó‡±Å‡∞∞‡∞ø‡∞Ç‡∞ö‡∞ø': 'about',
            '‡∞ö‡±Ü‡∞Ç‡∞¶‡∞ø': 'regarding',
            '‡∞µ‡∞∞‡∞ï‡±Å': 'until',
            '‡∞≤‡∞æ‡∞ó‡∞æ': 'like',
            '‡∞™‡±ä‡∞Ç‡∞¶‡∞ø': 'having',
        }

    def detect_case(self, word: str) -> Tuple[Optional[str], Optional[str], float]:
        """Detect case and root with confidence scoring"""
        # Direct base form match (highest confidence)
        if word in self.base_forms:
            return 'Nominative', word, 0.98
        
        # Check each case pattern
        for case, patterns in self.case_patterns.items():
            for pattern, root_base in patterns:
                if case == 'Genitive':
                    # Genitive patterns are prefixes
                    if word.startswith(pattern.replace('^', '')):
                        remaining = word[len(pattern.replace('^', '')):]
                        # Check if remaining part is a compound suffix
                        if not remaining or remaining in self.compound_suffixes:
                            return case, root_base, 0.95
                else:
                    # Other cases are suffixes
                    if re.search(pattern, word):
                        root = re.sub(pattern, '', word)
                        # Verify this is a valid root
                        if root in [r.replace('^', '') for r in [p[1] for p in self.case_patterns[case]]]:
                            return case, root_base, 0.90
        
        # Check for compound forms (oblique + postposition)
        for oblique_root in ['‡∞®‡∞æ', '‡∞Æ‡∞æ', '‡∞®‡±Ä', '‡∞Æ‡±Ä', '‡∞Ö‡∞§‡∞®‡∞ø', '‡∞Ü‡∞Æ‡±Ü', '‡∞§‡∞®']:
            if word.startswith(oblique_root) and len(word) > len(oblique_root):
                suffix = word[len(oblique_root):]
                if suffix in self.compound_suffixes:
                    # Map oblique root back to base
                    base_map = {
                        '‡∞®‡∞æ': '‡∞®‡±á‡∞®‡±Å', '‡∞Æ‡∞æ': '‡∞Æ‡±á‡∞Æ‡±Å', '‡∞®‡±Ä': '‡∞®‡±Å‡∞µ‡±ç‡∞µ‡±Å', 
                        '‡∞Æ‡±Ä': '‡∞Æ‡±Ä‡∞∞‡±Å', '‡∞Ö‡∞§‡∞®‡∞ø': '‡∞Ö‡∞§‡∞®‡±Å', '‡∞Ü‡∞Æ‡±Ü': '‡∞Ü‡∞Æ‡±Ü', '‡∞§‡∞®': '‡∞§‡∞æ‡∞®‡±Å'
                    }
                    base = base_map.get(oblique_root, oblique_root)
                    return f"Genitive+{suffix}", base, 0.85
        
        return None, None, 0.0

    def analyze(self, word: str) -> Optional[Dict[str, Any]]:
        """Comprehensive pronoun analysis"""
        word = word.strip()
        
        # Detect case and root
        case, root, confidence = self.detect_case(word)
        
        if case and root and root in self.base_forms:
            base_info = self.base_forms[root].copy()
            
            # Enhanced description based on case
            case_descriptions = {
                'Nominative': 'Subject form',
                'Accusative': 'Object form (receives action)',
                'Dative': 'Indirect object (to/for)',
                'Genitive': 'Possessive form (of/belonging to)',
                'Instrumental': 'Instrumental (with/using)',
                'Locative': 'Locative (in/at/on)',
                'Ablative': 'Ablative (from)',
            }
            
            description = case_descriptions.get(case, f'{case} form')
            
            # Handle compound forms specially
            if '+' in case:
                base_case, suffix = case.split('+')
                description = f"{case_descriptions.get(base_case, base_case)} + '{suffix}' ({self.compound_suffixes.get(suffix, 'unknown')})"
                case = base_case
            
            return {
                'root': root,
                'type': 'PRONOUN',
                'case': case,
                'description': description,
                'details': base_info,
                'confidence': confidence,
                'english_equivalent': self._get_english_equivalent(root, case, base_info)
            }
        
        return None

    def _get_english_equivalent(self, root: str, case: str, base_info: Dict) -> str:
        """Generate English equivalent based on case"""
        base_eng = base_info['eng']
        
        case_equivalents = {
            'Nominative': base_eng,
            'Accusative': f'me/us/you' if base_eng in ['I', 'We', 'You'] else f'him/her/it',
            'Dative': f'to {base_eng.lower()}',
            'Genitive': f'my/our/your' if base_eng in ['I', 'We', 'You'] else f'his/her/its',
            'Instrumental': f'with {base_eng.lower()}',
            'Locative': f'in {base_eng.lower()}',
            'Ablative': f'from {base_eng.lower()}',
        }
        
        return case_equivalents.get(case, base_eng)

    def analyze_sentence(self, sentence: str) -> List[Dict[str, Any]]:
        """Find and analyze all pronouns in a sentence"""
        # Simple Telugu tokenization
        words = re.findall(r'[\u0C00-\u0C7F]+', sentence)
        pronouns = []
        
        for word in words:
            analysis = self.analyze(word)
            if analysis:
                analysis['original'] = word
                pronouns.append(analysis)
        
        return pronouns

    def get_pronoun_paradigm(self, base_pronoun: str) -> Dict[str, str]:
        """Generate all case forms for a given base pronoun"""
        if base_pronoun not in self.base_forms:
            return {}
        
        paradigm = {'Nominative': base_pronoun}
        
        # Generate common case forms (simplified)
        base_map = {
            '‡∞®‡±á‡∞®‡±Å': '‡∞®‡∞æ', '‡∞Æ‡±á‡∞Æ‡±Å': '‡∞Æ‡∞æ', '‡∞®‡±Å‡∞µ‡±ç‡∞µ‡±Å': '‡∞®‡±Ä', 
            '‡∞Æ‡±Ä‡∞∞‡±Å': '‡∞Æ‡±Ä', '‡∞Ö‡∞§‡∞®‡±Å': '‡∞Ö‡∞§‡∞®‡∞ø', '‡∞Ü‡∞Æ‡±Ü': '‡∞Ü‡∞Æ‡±Ü', '‡∞§‡∞æ‡∞®‡±Å': '‡∞§‡∞®'
        }
        
        oblique_base = base_map.get(base_pronoun, '')
        if oblique_base:
            paradigm.update({
                'Accusative': f'{oblique_base}‡∞®‡±ç‡∞®‡±Å' if base_pronoun in ['‡∞®‡±á‡∞®‡±Å', '‡∞®‡±Å‡∞µ‡±ç‡∞µ‡±Å'] else f'{oblique_base}‡∞®‡±Å',
                'Dative': f'{oblique_base}‡∞ï‡±Å',
                'Genitive': oblique_base,
                'Instrumental': f'{oblique_base}‡∞§‡±ã',
                'Locative': f'{oblique_base}‡∞≤‡±ã',
            })
        
        return paradigm


# ==========================================
# COMPREHENSIVE TESTING
# ==========================================
def main():
    engine = AdvancedPronounEngine()
    
    # Comprehensive test cases
    test_words = [
        # Base forms
        "‡∞®‡±á‡∞®‡±Å", "‡∞Æ‡±á‡∞Æ‡±Å", "‡∞®‡±Å‡∞µ‡±ç‡∞µ‡±Å", "‡∞Æ‡±Ä‡∞∞‡±Å", "‡∞Ö‡∞§‡∞®‡±Å", "‡∞Ü‡∞Æ‡±Ü", "‡∞Ö‡∞¶‡∞ø", "‡∞µ‡∞æ‡∞∞‡±Å",
        
        # Case forms
        "‡∞®‡∞æ‡∞ï‡±Å", "‡∞Æ‡∞æ‡∞ï‡±Å", "‡∞®‡±Ä‡∞ï‡±Å", "‡∞Æ‡±Ä‡∞ï‡±Å", "‡∞Ö‡∞§‡∞®‡∞ø‡∞ï‡∞ø", 
        "‡∞®‡∞®‡±ç‡∞®‡±Å", "‡∞Æ‡∞Æ‡±ç‡∞Æ‡∞≤‡±ç‡∞®‡∞ø", "‡∞®‡∞ø‡∞®‡±ç‡∞®‡±Å", "‡∞Æ‡∞ø‡∞Æ‡±ç‡∞Æ‡∞≤‡±ç‡∞®‡∞ø", "‡∞Ö‡∞§‡∞®‡±ç‡∞®‡∞ø",
        "‡∞®‡∞æ", "‡∞Æ‡∞æ", "‡∞®‡±Ä", "‡∞Æ‡±Ä", "‡∞Ö‡∞§‡∞®‡∞ø", "‡∞§‡∞®",
        "‡∞®‡∞æ‡∞§‡±ã", "‡∞Æ‡∞æ‡∞§‡±ã", "‡∞®‡±Ä‡∞§‡±ã", "‡∞Æ‡±Ä‡∞§‡±ã",
        "‡∞®‡∞æ‡∞≤‡±ã", "‡∞Æ‡∞æ‡∞≤‡±ã", "‡∞®‡±Ä‡∞≤‡±ã",
        
        # Compound forms
        "‡∞®‡∞æ‡∞ï‡±ã‡∞∏‡∞Ç", "‡∞Æ‡∞æ‡∞µ‡∞≤‡±ç‡∞≤", "‡∞Ö‡∞§‡∞®‡∞ø‡∞¶‡±ç‡∞µ‡∞æ‡∞∞‡∞æ", "‡∞®‡∞æ‡∞ó‡±Å‡∞∞‡∞ø‡∞Ç‡∞ö‡∞ø",
        
        # Reflexive and interrogative
        "‡∞§‡∞æ‡∞®‡±Å", "‡∞§‡∞®", "‡∞é‡∞µ‡∞∞‡±Å", "‡∞è‡∞Æ‡∞ø", "‡∞é‡∞µ‡∞°‡±Å",
        
        # Emphatic forms
        "‡∞®‡±á‡∞®‡±á", "‡∞Ö‡∞¶‡±á", "‡∞á‡∞¶‡±á"
    ]
    
    print("üß™ ADVANCED TELUGU PRONOUN ANALYZER")
    print("=" * 100)
    print(f"{'PRONOUN':<12} | {'ROOT':<10} | {'CASE':<20} | {'PERSON/NUMBER':<15} | {'ENGLISH':<20} | {'CONF'}")
    print("-" * 100)
    
    results = []
    for word in test_words:
        analysis = engine.analyze(word)
        if analysis:
            details = analysis['details']
            person_num = f"{details['person']}/{details['number']}"
            print(f"{word:<12} | {analysis['root']:<10} | {analysis['case']:<20} | {person_num:<15} | {analysis['english_equivalent']:<20} | {analysis['confidence']:.2f}")
            results.append(analysis)
    
    # Sentence analysis demo
    print(f"\nüìù SENTENCE ANALYSIS DEMO:")
    print("=" * 100)
    test_sentences = [
        "‡∞®‡±á‡∞®‡±Å ‡∞®‡∞æ ‡∞™‡±Å‡∞∏‡±ç‡∞§‡∞ï‡∞Ç ‡∞®‡±Ä‡∞ï‡±Å ‡∞á‡∞∏‡±ç‡∞§‡∞æ‡∞®‡±Å",
        "‡∞Ö‡∞§‡∞®‡±Å ‡∞Ö‡∞§‡∞®‡∞ø ‡∞§‡∞≤‡±ç‡∞≤‡∞ø‡∞§‡±ã ‡∞Æ‡∞æ‡∞ü‡±ç‡∞≤‡∞æ‡∞°‡∞§‡∞æ‡∞°‡±Å",
        "‡∞Æ‡±Ä‡∞∞‡±Å ‡∞Æ‡±Ä ‡∞á‡∞≤‡±ç‡∞≤‡±Å ‡∞µ‡∞æ‡∞∞‡∞ø‡∞ï‡∞ø ‡∞ö‡±Ç‡∞™‡∞ø‡∞Ç‡∞ö‡∞æ‡∞∞‡∞æ?"
    ]
    
    for sentence in test_sentences:
        print(f"\nSentence: {sentence}")
        pronouns = engine.analyze_sentence(sentence)
        for p in pronouns:
            print(f"  {p['original']:<8} -> {p['case']:<15} ({p['english_equivalent']})")
    
    # Paradigm generation demo
    print(f"\nüìö PRONOUN PARADIGM DEMO:")
    print("=" * 100)
    for base in ["‡∞®‡±á‡∞®‡±Å", "‡∞Ö‡∞§‡∞®‡±Å", "‡∞Æ‡±Ä‡∞∞‡±Å"]:
        paradigm = engine.get_pronoun_paradigm(base)
        print(f"\n{base} paradigm:")
        for case, form in paradigm.items():
            print(f"  {case:<15}: {form}")

if __name__ == "__main__":
    main()
